#!/usr/bin/env python3
"""
ä¸­æ–‡å­—æ•°ç»Ÿè®¡è„šæœ¬
å‡†ç¡®ç»Ÿè®¡ä¸­æ–‡æ–‡ç« å­—æ•°ï¼ˆåŒ…æ‹¬ä¸­è‹±æ–‡ï¼‰
"""

import sys
import argparse
import re
from pathlib import Path


def count_chinese_chars(text):
    """ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ•°"""
    return sum(1 for char in text if '\u4e00' <= char <= '\u9fff')


def count_english_words(text):
    """ç»Ÿè®¡è‹±æ–‡å•è¯æ•°"""
    # ç§»é™¤ä¸­æ–‡å­—ç¬¦
    text_without_chinese = re.sub(r'[\u4e00-\u9fff]', ' ', text)
    # æŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²
    words = re.findall(r'\b[a-zA-Z]+\b', text_without_chinese)
    return len(words)


def count_paragraphs(text):
    """ç»Ÿè®¡æ®µè½æ•°"""
    paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
    return len(paragraphs)


def count_sentences(text):
    """ç»Ÿè®¡å¥å­æ•°"""
    # ç®€å•ç»Ÿè®¡ï¼šæŒ‰ä¸­è‹±æ–‡å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    return len(sentences)


def remove_markdown_syntax(text):
    """ç§»é™¤Markdownè¯­æ³•ï¼Œåªä¿ç•™æ­£æ–‡"""
    # ç§»é™¤ä»£ç å—
    text = re.sub(r'```[\s\S]*?```', '', text)
    # ç§»é™¤è¡Œå†…ä»£ç 
    text = re.sub(r'`[^`]+`', '', text)
    # ç§»é™¤å›¾ç‰‡
    text = re.sub(r'!\[([^\]]*)\]\([^\)]+\)', '', text)
    # ç§»é™¤é“¾æ¥ä½†ä¿ç•™æ–‡å­—
    text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
    # ç§»é™¤æ ‡é¢˜æ ‡è®°
    text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)
    # ç§»é™¤ç²—ä½“ã€æ–œä½“æ ‡è®°
    text = re.sub(r'\*\*([^\*]+)\*\*', r'\1', text)
    text = re.sub(r'\*([^\*]+)\*', r'\1', text)
    text = re.sub(r'__([^_]+)__', r'\1', text)
    text = re.sub(r'_([^_]+)_', r'\1', text)
    # ç§»é™¤HTMLæ ‡ç­¾
    text = re.sub(r'<[^>]+>', '', text)
    # ç§»é™¤åˆ†éš”çº¿
    text = re.sub(r'^-{3,}$', '', text, flags=re.MULTILINE)
    text = re.sub(r'^â•{3,}$', '', text, flags=re.MULTILINE)

    return text


def analyze_text(file_path, remove_markdown=True):
    """åˆ†ææ–‡æœ¬æ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        text = f.read()

    original_text = text

    if remove_markdown:
        text = remove_markdown_syntax(text)

    # ç»Ÿè®¡å„é¡¹æŒ‡æ ‡
    chinese_chars = count_chinese_chars(text)
    english_words = count_english_words(text)
    total_words = chinese_chars + english_words
    paragraphs = count_paragraphs(text)
    sentences = count_sentences(text)
    total_chars = len(text)
    total_chars_original = len(original_text)

    # ä¼°ç®—é˜…è¯»æ—¶é—´ï¼ˆä¸­æ–‡çº¦300å­—/åˆ†é’Ÿï¼‰
    reading_time_min = total_words / 300
    reading_time_max = total_words / 250

    return {
        'chinese_chars': chinese_chars,
        'english_words': english_words,
        'total_words': total_words,
        'paragraphs': paragraphs,
        'sentences': sentences,
        'total_chars': total_chars,
        'total_chars_original': total_chars_original,
        'reading_time_min': reading_time_min,
        'reading_time_max': reading_time_max,
    }


def format_number(num):
    """æ ¼å¼åŒ–æ•°å­—ï¼Œæ·»åŠ åƒä½åˆ†éš”ç¬¦"""
    return f"{num:,}"


def main():
    parser = argparse.ArgumentParser(description='ç»Ÿè®¡ä¸­æ–‡æ–‡ç« å­—æ•°')
    parser.add_argument('file_path', help='æ–‡æœ¬æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--keep-markdown', action='store_true',
                       help='ä¿ç•™Markdownè¯­æ³•ï¼ˆä¸ç§»é™¤ï¼‰')
    parser.add_argument('--json', action='store_true',
                       help='ä»¥JSONæ ¼å¼è¾“å‡º')

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶
    file_path = Path(args.file_path)
    if not file_path.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ï¼š{file_path}")
        sys.exit(1)

    try:
        # åˆ†ææ–‡æœ¬
        stats = analyze_text(file_path, remove_markdown=not args.keep_markdown)

        if args.json:
            # JSONæ ¼å¼è¾“å‡º
            import json
            print(json.dumps(stats, indent=2, ensure_ascii=False))
        else:
            # å‹å¥½æ ¼å¼è¾“å‡º
            print()
            print("=" * 60)
            print(f"  æ–‡ä»¶ï¼š{file_path.name}")
            print("=" * 60)
            print()
            print("ğŸ“Š å­—æ•°ç»Ÿè®¡ï¼š")
            print(f"  â€¢ ä¸­æ–‡å­—ç¬¦ï¼š{format_number(stats['chinese_chars'])} å­—")
            print(f"  â€¢ è‹±æ–‡å•è¯ï¼š{format_number(stats['english_words'])} è¯")
            print(f"  â€¢ æ€»å­—æ•°ï¼š{format_number(stats['total_words'])} å­—")
            print()
            print("ğŸ“ ç»“æ„ç»Ÿè®¡ï¼š")
            print(f"  â€¢ æ®µè½æ•°ï¼š{format_number(stats['paragraphs'])} æ®µ")
            print(f"  â€¢ å¥å­æ•°ï¼š{format_number(stats['sentences'])} å¥")
            print(f"  â€¢ æ€»å­—ç¬¦ï¼š{format_number(stats['total_chars'])} å­—ç¬¦")
            if not args.keep_markdown:
                print(f"  â€¢ åŸå§‹å­—ç¬¦ï¼ˆå«Markdownï¼‰ï¼š{format_number(stats['total_chars_original'])} å­—ç¬¦")
            print()
            print("â±ï¸  é˜…è¯»æ—¶é—´ï¼š")
            print(f"  â€¢ é¢„è®¡é˜…è¯»ï¼š{stats['reading_time_min']:.1f} - {stats['reading_time_max']:.1f} åˆ†é’Ÿ")
            print(f"  â€¢ çº¦ {int(round(stats['reading_time_min'] + stats['reading_time_max']) / 2)} åˆ†é’Ÿ")
            print()
            print("=" * 60)

    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
